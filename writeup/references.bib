@article{bailensonNonverbalOverloadTheoretical2021,
  title = {Nonverbal Overload: {{A}} Theoretical Argument for the Causes of {{Zoom}} Fatigue.},
  shorttitle = {Nonverbal Overload},
  author = {Bailenson, Jeremy N.},
  date = {2021-02-23},
  journaltitle = {Technology, Mind, and Behavior},
  shortjournal = {Technology, Mind, and Behavior},
  volume = {2},
  number = {1},
  issn = {2689-0208},
  doi = {10.1037/tmb0000030},
  url = {https://tmb.apaopen.org/pub/nonverbal-overload},
  urldate = {2025-11-23},
  abstract = {For decades, scholars have predicted that videoconference technology will disrupt the practice of commuting daily to and from work and will change the way people socialize. In 2020, the Covid-19 pandemic forced a drastic increase in the number of videoconference meetings, and Zoom became the leading software package because it was free, robust, and easy to use. While the software has been an essential tool for productivity, learning, and social interaction, something about being on videoconference all day seems particularly exhausting, and the term “Zoom Fatigue” caught on quickly. In this article, I focus on nonverbal overload as a potential cause for fatigue and provide four arguments outlining how various aspects of the current Zoom interface likely lead to psychological consequences. The arguments are based on academic theory and research, but also have yet to be directly tested in the context of Zoom, and require future experimentation to confirm. Instead of indicting the medium, my goal is to point out these design flaws to isolate research areas for social scientists and to suggest design improvements for technologists.},
  langid = {english},
  file = {/Users/davidbarnstone/Library/CloudStorage/GoogleDrive-dbarnsto@stanford.edu/My Drive/PDFs/Bailenson - 2021 - Nonverbal overload A theoretical argument for the causes of Zoom fatigue..pdf}
}

@online{fauvilleNonverbalMechanismsPredict2021,
  type = {SSRN Scholarly Paper},
  title = {Nonverbal Mechanisms Predict {{Zoom}} Fatigue and Explain Why Women Experience Higher Levels than Men},
  author = {Fauville, Geraldine and Luo, Mufan and Muller Queiroz, Anna Carolina and Bailenson, Jeremy N. and Hancock, Jeff},
  date = {2021-04-05},
  number = {3820035},
  eprint = {3820035},
  eprinttype = {Social Science Research Network},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.3820035},
  url = {https://papers.ssrn.com/abstract=3820035},
  urldate = {2025-11-23},
  abstract = {There is little data on Zoom Fatigue, the exhaustion that follows video conference meetings. This paper administers the Zoom Exhaustion \& Fatigue scale to 10,591 participants from a convenience sample and tests the associations between five theoretical nonverbal mechanisms and Zoom Fatigue – mirror anxiety, being physically trapped, hyper gaze from a grid of staring faces, and the cognitive load from producing and interpreting nonverbal cues. First, we show that daily usage predicts the amount of fatigue, and that women have longer meetings and shorter breaks between meetings than men. Second, we show that women have greater Zoom fatigue than men. Third, we show that the five nonverbal mechanisms for fatigue predict Zoom fatigue. Fourth, we confirm that mirror anxiety mediates the difference in fatigue across gender. Exploratory research shows that race, age, and personality relate to fatigue. We discuss avenues for future research and strategies to decrease Zoom fatigue.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Gender,Nonverbal Communication,Video Conference,Zoom Fatigue},
  file = {/Users/davidbarnstone/Library/CloudStorage/GoogleDrive-dbarnsto@stanford.edu/My Drive/PDFs/Fauville et al. - 2021 - Nonverbal Mechanisms Predict Zoom Fatigue and Explain Why Women Experience Higher Levels than Men.pdf}
}

@incollection{griffinMediaEcologyMarshall2019,
  title = {Media Ecology of {{Marshall McLuhan}}},
  booktitle = {A First Look at Communication Theory},
  author = {Griffin, Em and Ledbetter, Andrew and Sparks, Glenn, Sparks},
  date = {2019},
  edition = {10},
  pages = {309--319},
  publisher = {McGraw Hill Education},
  location = {New York, NY},
  file = {/Users/davidbarnstone/Library/CloudStorage/GoogleDrive-dbarnsto@stanford.edu/My Drive/PDFs/Griffin et al. - 2019 - Media ecology of Marshall McLuhan.pdf}
}

@software{lenthEmmeansEstimatedMarginal2025,
  title = {Emmeans: {{Estimated Marginal Means}}, Aka {{Least-Squares Means}}},
  author = {Lenth, Russell V. and Piaskowski, Julia},
  date = {2025},
  url = {https://rvlenth.github.io/emmeans/},
  version = {R package version 2.0.0}
}

@software{rcoreteamLanguageEnvironmentStatistical2025,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical}}                   {{Computing}}},
  author = {{R Core Team}},
  date = {2025},
  location = {Vienna, Austria},
  url = {https://www.R-project.org},
  organization = {R Foundation for Statistical Computing}
}

@article{walter-terrillSuperficialAuditoryDisfluency2025,
  title = {Superficial Auditory (Dis)Fluency Biases Higher-Level Social Judgment},
  author = {Walter-Terrill, Robert and Ongchoco, Joan Danielle K. and Scholl, Brian J.},
  date = {2025-04},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {122},
  number = {13},
  pages = {e2415254122},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2415254122},
  url = {https://pnas.org/doi/10.1073/pnas.2415254122},
  urldate = {2025-09-30},
  abstract = {When talking to other people, we naturally form impressions based not only on what they say but also on how they say it—e.g., how confident they sound. In modern life, however, the sounds of voices are often determined not only by intrinsic qualities (such as vocal anatomy) but also by extrinsic properties (such as videoconferencing microphone quality). Here, we show that such superficial auditory properties can have surprisingly deep consequences for higher-level social judgments. Listeners heard short narrated passages (e.g., from job application essays) and then made various judgments about the speakers. Critically, the recordings were modified to simulate different microphone qualities, while carefully equating listeners’ comprehension of the words. Though the manipulations carried no implications about the speakers themselves, common disfluent auditory signals (as in “tinny” speech) led to decreased judgments of intelligence, hireability, credibility, and romantic desirability. These effects were robust across speaker gender and accent, and they occurred for both human and clearly artificial (computer-synthesized) speech. Thus, just as judgments from written text are influenced by factors such as font fluency, judgments from speech are not only based on its content but also biased by the superficial vehicle through which it is delivered. Such effects may become more relevant as daily communication via videoconferencing becomes increasingly widespread.},
  langid = {english},
  file = {/Users/davidbarnstone/Library/CloudStorage/GoogleDrive-dbarnsto@stanford.edu/My Drive/PDFs/Walter-Terrill et al. - 2025 - Superficial auditory (dis)fluency biases higher-level social judgment.pdf}
}
