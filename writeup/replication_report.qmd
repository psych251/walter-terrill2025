---
title: "Replication of Superficial Auditory (Dis)fluency Biases Higher-Level Social Judgment by Walter-Terrill, Ongchoco & Scholl (2025, Proceedings of the National Academy of Sciences)"
author: "David Barnstone (dbarnsto@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: references.bib
csl: apa.csl
format:
  html:
    toc: true
    toc_depth: 3
---

```{r load libraries, include = FALSE}
library("pwr")           # for power analyses
library("tidyverse")     # for data wrangling
library("knitr")         # for knitting RMarkdown
library("here")          # for managing file paths
library("ggbeeswarm")    # for beeswarm plots
library("effectsize")
```

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

Human interpersonal communication is increasingly mediated by videoconferencing technology. Platforms like Zoom allow users to see themselves but not hear themselves. @walter-terrillSuperficialAuditoryDisfluency2025 found that participants rated a job candidate more favorably when the audio quality of their application statement was clear vs. distorted but otherwise comprehensible. This finding provides empirical support for the influential communication theory media ecology, which suggests characteristics of the medium through which a message is delivered may affect people independently of the content of the message itself. Practically, microphone quality represents a relatively simple target for intervention that could increase a family's socioeconomic status if it is indeed critical in hiring decisions. The increasingly popularity of podcasts as news sources could also affect how listeners judge the quality of information presented, regardless of the content. @bailensonNonverbalOverloadTheoretical2021

The target of this replication is Experiment 4, in which 1200 participants from the Prolific platform were randomly assigned to the clear or distorted audio conditions (600 in each group). After listening to the audio statement, participants rated how likely they would be to hire the candidate on a continuous scale from 0 to 100. I will additionally conduct several exploratory analyses with the goal of generating hypotheses to test in future work.

2)  Apparatus and data cleaning: The authors used custom webpages built from jsPsych libraries and a custom matching algorithm to assess the accuracy of the transcriptions. If they are not able or willing to provide these materials, they would need be recreated. Imperfect transcripts were manually checked by two coders, adding time, effort, and complexity to the procedure.

[Repository](https://github.com/psych251/walter-terrill2025)

[Original paper](https://github.com/psych251/walter-terrill2025/blob/main/original_paper/walter-terrill-et-al-2025.pdf)

## Methods

### Power Analysis

#### Original Study

Table 1 displays the results of a post-hoc power analysis for the original study's Experiment 4 as well as Experiments 1 and 5 (briefly explain what these are).

```{r power analysis_original}
# calculate original study's power
pwr_original = tibble(experiment = c(
  "Exp. 1: Hireability",
  "Exp. 4: Hireability",
  "Exp. 5: Intelligence"),
  voice_type = c("Human", "Computer", "Computer"),
  n_per_group = c(300, 600, 600),
  total_n = c(600, 1200, 1200),
  effect_size = c(0.35, 0.43, 0.20)) %>%
  mutate(power = map2_dbl(
    n_per_group,
    effect_size,
    ~{pwr.t.test(n = .x,
                 d = .y,
                 sig.level = 0.05,
                 type = "two.sample",
                 alternative = "two.sided")$power}))

pwr_original %>%
  kable(caption =
          "Table 1. Original Study Power Analysis (post hoc)",
        digits = 2,
        col.names = c("Experiment", "Voice", "n per Group",
                      "Total N", "Effect Size (d)", "Power"))
```

#### Replication

Because @walter-terrillSuperficialAuditoryDisfluency2025 found a significant effect of audio quality on social judgement across voice types (male, female, American, British, human, and artificial) and contexts (hireability, romantic desirability, and credibility), my power analysis pools across voice type to determine the total N needed to achieve 80-95% power (Table 2).

```{r power analysis_replication}
# calculate total sample size needed for 3 power levels
pooled_analysis <- tibble(analysis = "Audio quality main effect (pooled)",
                          effect_size = 0.43) # from Exp. 4

pooled_power = pooled_analysis %>%
  mutate(
    n_80 = map_dbl(effect_size, ~ceiling(
      pwr.t.test(d = .x,
               power = 0.80,
               sig.level = 0.05,
               type = "two.sample")$n)),
    n_90 = map_dbl(effect_size, ~ceiling(
      pwr.t.test(d = .x,
                 power = 0.90,
                 sig.level = 0.05, 
                 type = "two.sample")$n)),
    n_95 = map_dbl(effect_size, ~ceiling(
      pwr.t.test(d = .x,
                 power = 0.95,
                 sig.level = 0.05, 
                 type = "two.sample")$n)),
    `80%` = n_80 * 2,
    `90%` = n_90 * 2,
    `95%` = n_95 * 2)

pooled_power %>%
  select(analysis, effect_size, `80%`, `90%`, `95%`) %>%
  kable(caption = "Table 2. Replication Power Analysis (a priori)",
        col.names = c("Analysis", "Effect Size (d)", "80% Power", "90% Power", "95% Power"))
  
# final power analysis
pwr = pwr.t.test(n = 125,
                 d = 0.43,
                 sig.level = 0.05,
                 power = NULL,
                 type = "two.sample",
                 alternative = "two.sided")$power
```

### Planned Sample

> Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.

Based on the above power analysis, I will recruit 250 participants from Prolific to yield `{r} round(pwr*100, digits = 1)`% power to detect the main effect of audio quality. Participants will be prescreened using the criteria from the original study:

> "Prescreening criteria required listeners to have English as a first language, a Prolific approval rating of at least 95%, previous completion of at least 100 Prolific studies, no prior participation in another experiment from this project, and the use of a laptop or desktop computer (but not a phone or tablet)." [@walter-terrillSuperficialAuditoryDisfluency2025]

The study will remain active on the Prolific platform until 250 submissions are received. As this study involves random assignment to one of four conditions (see below), this sampling strategy may result in slight differences in n per group which will be reported.

### Materials

This replication will use four of the eight audio stimuli from the original study, which are available in the repo and were also published with the PNAS paper.

#### Human voice

The human voice recording will be identical to the original. It was prepared by the original authors as follows:

> "The Clear audio stimulus (in mp3 format) was a recorded narration by a naive male speaker. The recording (Audio S1) was 27.5 s and consisted of the following spoken text: 'After 8 y in sales, I am currently seeking a new challenge which will utilize my meticulous attention to detail, and friendly, professional manner. I am an excellent fit for your company and will be an asset to your team as a senior sales manager. As an experienced sales manager with my previous company, my tenacious and proactive approach resulted in numerous important contract wins. Through this experience, I have improved and developed my networking skills, which have proven to be very effective in increasing my number of sales.'” [@walter-terrillSuperficialAuditoryDisfluency2025]

#### Computer voice

The artificial voice recording will be identical to the original. It was created by the original authors using Amazon Polly (https://aws.amazon.com/polly/):

> "The audio stimulus (Audios S7 and S8) was generated (as in Experiment 3) using a simulated male American English voice (“Matthew”). The recording was 28.5 s long and consisted of the same text as used in Experiment 1." [@walter-terrillSuperficialAuditoryDisfluency2025]

#### Audio quality manipulation

The distorted audio stimuli will be identical to the original. They were prepared by the original authors as follows:

> "The Distorted audio stimulus (Audio S2) was created by modifying the Clear recording using the open-source VST effect “MDACombo” (42) in the TwistedWave Online Audio Editor (https://twistedwave.com/online), with the following settings: Model: 4x12\>; Drive: –55; Bias: 83; Output: 0; Process HPF Frequency: 20%; HPF Resolution: 90%. This resulted in speech that was fully comprehensible, but that had a high-frequency tinny quality like that commonly experienced during videoconferences with a low-quality computer microphone." [@walter-terrillSuperficialAuditoryDisfluency2025]

### Procedure

The experimental procedure will be identical to the original except as noted below:

> "All experiments were completed on custom webpages created with software written in a combination of PHP, JavaScript, CSS, and HTML, with the jsPsych libraries (40). Before beginning each experiment, listeners were asked to either wear headphones or move to a quiet environment. To discourage multitasking, listeners completed the experiment with their browser in full-screen mode. During debriefing, listeners reported whether they heard the stimuli using speakers or headphones." [@walter-terrillSuperficialAuditoryDisfluency2025]

Participants will be randomly assigned to one of four conditions using a between-subjects, 2 (voice type: computer or human) x 2 (audio quality: clear or distorted) design.

> "Listeners first heard a short audio recording which confirmed that they could hear speech, and which allowed them to adjust the volume to a comfortable level...Listeners were then presented with the following centered written prompts \[across a few separate screens, with all written text presented in black “Open Sans” font, scaled to a point size that was 1.5% of the full-screen pixel width of the listener’s display, on a light gray (#D3D3D3) background\]: “For this study, we’d like you to imagine that as part of your job, you are tasked with making a hiring decision for a highly competitive position: senior sales manager. You will listen to a few lines from a personal statement from an application for this position. We will then ask you a few questions about your impressions of the personal statement and its author. Click on the ‘Play’ button below to play the audio clip of the personal statement. You will only be able to listen to this once. (You cannot replay it.)” Listeners then heard the audio stimuli after clicking on the relevant button (which then disappeared). After the recording finished playing, listeners were asked “What is the likelihood that you would hire this person?”, and responded by using their computer mouse to position a slider (a light blue circle 35px in diameter) on a continuous scale (depicted by a white bar, 25px high, with a width equal to 75% of the full-screen width) from Very Unlikely to Very Likely (with these terms appearing just below the bar on the far left and right, respectively). (Listeners could adjust the marker’s position as many times as they wished, after which they clicked on a “Continue” button.) Responses were recorded as values ranging from 0 (matching the bar’s far left) to 100 (representing the bar’s far right). [@walter-terrillSuperficialAuditoryDisfluency2025]

In addition to the hireability question, participants will also respond to the intelligence question from the original study's Experiment 4: "How intelligent is the author of this personal statement?" The scale will also be continuous, from 0 ("Very Unintelligent) to 100 ("Very Intelligent"). The order of the questions will be counterbalanced. Finally, participants will answer the following follow-up questions during debriefing:

1.  Demographics: Age (textbox), Gender (select one: Male, Female, Other, Prefer not to say)
2.  How are you listening to the audio from experiment? (select one: Headphones, Laptop Speakers, External Speakers, Earbuds, Other)
3.  In 1-2 sentences, what do you think this experiment was testing? (text box)
4.  Did you experience any technical difficulties in playing the audio or did anything distract you while you were listening to the audio? If so please describe. (This will not affect whether you receive credit or compensation.) (text box)
5.  Using the slider below, on a scale of 1-100 (with 1 being very distracted, and 100 being very focused), how well did you pay attention to the experiment? (This will not affect whether you receive credit or compensation.)
6.  Have you ever been employed in a position where you made hiring decisions? (Yes or No)
7.  Using the slider below, on a scale of 1-100, how would you rate the recording quality of the audio clip you just heard? (With 1 being very poor, and 100 being excellent.)
8.  Using the slider below, on a scale of 1-100, how well were you able to understand the words spoken in the audio clip you heard -- setting aside any possible issues with the recording quality? (With 0 being you understood none of the words, 50 being you understood about half of the words, and 100 being you understood all the words.) (No Understanding to Complete Understanding)
9.  Is there anything else we should know (either about you or how you did the experiment) that may have had an impact on your results? (text box)

Debriefing:

Thank you for completing this experiment! I really appreciate your help with this experiment and making it through to the end. Your participation will help us better understand how audio quality influences the judgements we make about other people.

To get credit for this experiment, please click on continue, which will redirect you to the completion page on Prolific.

### Analysis Plan

The primary analysis of this replication will follow the original study:

> "The dependent measure was the “hireability” rating listeners gave after hearing the narrated personal statement. A between-samples two-tailed t test was used to determine whether the average ratings differed significantly between the Clear and Distorted conditions." [@walter-terrillSuperficialAuditoryDisfluency2025]

I will also conduct several exploratory analyses to assess the main effect of voice type (computer or human) and the interaction between audio quality and voice type.

Both the confirmatory and exploratory analyses will be conducted using a linear model in the form of:

{{< include _shared/eq-linear-model.qmd >}}

where

$Y_i$ is the hireability rating for participant $i$,\
$\beta_0$ is the mean hireability rating for the clear computer voice,\
$\beta_1$ is the main effect of the distorted computer voice,\
$\beta_2$ is the main effect of the clear human voice,\
$\beta_3$ is the moderation of the effect by voice type, and\
$\epsilon_i$ is the error term.

The confirmatory analysis will be conducted using a two way analysis of variance (ANOVA).

Additionally, I will rule out the potential confounds of question order, listening device, attention, and comprehension by conducting an independent t-test, one-way ANOVA, and correlation analyses, respectively.

The lack of a significant interaction effect will support my pooling strategy and bolster the interpretation of the main effect of audio quality.

Finally, I will examine within-person coupling between hireability and intelligence ratings.

All analyses will be conducted in R.

### Differences from Original Study

Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study. The goal, of course, is to minimize those differences, but differences will inevitably occur. Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect.

-   Instruction audio was clear in all conditions
-   Did not include transcription task (Exp 1), rely on self report of comprehensibility
-   Because the original study found that same effect across computer and human voices, I pooled across voice types to achieve greater power with the preregistered sample size

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample

Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan

Any differences from what was described as the original plan, or “none”.

## Results

### Data preparation

Data preparation following the analysis plan.

```{r}
### Data Preparation

#### Load Relevant Libraries and Functions

#### Import data
pilot_B <- read_csv(here("data", "pilot_B.csv")) %>%
  # remove identifying information
  select(-rt, -subject, -prolific_study_id,
         -prolific_session_id, -participant_id) %>%
  # create sequential subject ids
  # create anonymized data file
  write_csv(., "../data/pilot_B-anon.csv")

#### Data exclusion / filtering
remove_outliers <- function(x, threshold = 2.5) {
  mean_x <- mean(x, na.rm = TRUE)
  sd_x <- sd(x, na.rm = TRUE)
  abs(x - mean_x) <= threshold * sd_x
}

pilot_B = pilot_B %>% 
  filter(debrief_attention >= 70) %>% 
  filter(remove_outliers(hire_rt, threshold = 2.5)) %>% 
  filter(remove_outliers(intelligence_rt, threshold = 2.5)) %>% 
  filter(remove_outliers(debrief_understandable, threshold = 2))
# technical difficulties? make this question yes/no, TRUE/FALSE

#### Prepare data for analysis - create columns etc.
pilot_B = pilot_B %>%
  filter(data_summary == TRUE) %>% 
  select(-c(key_press, stimulus, trial_type, trial_index))

pilot_B = pilot_B %>% 
  mutate(distorted_audio = as.factor(distorted_audio),
         audio_quality = fct_recode(distorted_audio,
                                    "Clear" = "FALSE",
                                    "Distorted" = "TRUE"))
```

### Confirmatory analysis

The analyses as specified in the analysis plan.

*Side-by-side graph with original graph is ideal here*

```{r}
# insert figure from original paper
# include_graphics(here("writeup","replication_report_files", "walter-terrill2025_fig1_d.png"))

# plot of pilot B data pooled across voice type target n = 125 per group
ggplot(data = pilot_B,
       mapping = aes(x = audio_quality,
                     y = hire,
                     color = audio_quality)) +
  geom_beeswarm(cex = 10) +
  stat_summary(fun = mean,
               geom = "crossbar",
               width = 0.5,
               color = "grey") +
  scale_color_brewer(palette = "Set1") +
  labs(title = "Hireability judgments (pooled)",
       x = "Simulated audio quality",
       y = "Rating") +
  scale_y_continuous(breaks = seq(from = 0,
                                  to = 100,
                                  by = 10)) +
  theme_classic() +
  theme(text = element_text(size = 13)) +
  theme(plot.title = element_text(hjust = 0.5))

# analysis
t_test <- t.test(hire ~ audio_quality, data = pilot_B)
effect_size <- cohens_d(hire ~ audio_quality, data = pilot_B)

model = lm(hire ~ audio_quality + voice_type + audio_quality*voice_type,
           data = pilot_B)
summary(model)
```

### Exploratory analyses

Purpose of the following analyses are to generate hypotheses for future testing.

```{r}
# plot pooled intel ratings (Exp. 5)
ggplot(data = pilot_B,
       mapping = aes(x = audio_quality,
                     y = intelligence,
                     color = audio_quality)) +
  geom_beeswarm(cex = 10) +
  stat_summary(fun = mean,
               geom = "crossbar",
               width = 0.5,
               color = "grey") +
  scale_color_brewer(palette = "Set1") +
  labs(title = "Intellgience judgments (pooled across voice type)",
       x = "Simulated audio quality",
       y = "Rating") +
  scale_y_continuous(breaks = seq(from = 0,
                                  to = 100,
                                  by = 10)) +
  theme_classic()

# plot interaction voice type x audio quality
ggplot(data = pilot_B,
       mapping = aes(x = voice_type,
                     y = hire,
                     color = audio_quality,
                     group = audio_quality)) +
  stat_summary(fun.data = mean_cl_boot,
               geom = "pointrange",
               size = 0.5) +
  stat_summary(fun = mean,
               geom = "line",
               linewidth = 1) +
  scale_color_brewer(palette = "Set1") +
  labs(title = "Hireability x Voice Type",
       x = "voice type",
       y = "Rating") +
  scale_y_continuous(breaks = seq(from = 0,
                                  to = 100,
                                  by = 10)) +
  theme_classic()

model <- aov(hire ~ audio_quality * voice_type, data = pilot_B)
summary(model)

# moderation by hiring experience?

# within-person coupling 

```

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt. None of these need to be long.

### COI Disclosure

In the interest of transparency, I disclose that I occasionally work as an independent contractor for the National Academies of Sciences, the publisher of PNAS, where the original paper was published. Last year I was assigned to write a brief summary of this paper for the journal. However, I had no role in selecting this paper to cover nor relationships to the authors. My work for NAS/PNAS has no bearing on the journal's editorial decisions as research summaries are assigned only after acceptance.

## References

::: {#refs}
:::
